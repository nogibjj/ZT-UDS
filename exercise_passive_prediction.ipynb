{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Mortgage Delinquency Risk\n",
    "\n",
    "**Note: this is a new exercise, so if you find something weird, please bring it to my attention.**\n",
    "\n",
    "You have been hired by a mortgage servicing firm (a company that buys mortgages and then collects mortgage payments from homeowners) to build a model to answer the question: \n",
    "\n",
    "**Given all available information about a newly issued mortgage, what is the likelihood that the mortgage will enter delinquency (the homeowner will be at least 30 days late on a mortgage payment) during the first two years of the mortgage?**\n",
    "\n",
    "The servicer's hope, obviously, is to differentiate between mortgages to try and purchase (those that will be consistently paid) and mortgages they wish to avoid.\n",
    "\n",
    "For this task, you have been given [REAL data on a sample of all US Standard single family home mortgages purchased or insured by Freddie Mac](https://www.freddiemac.com/research/datasets/sf-loanlevel-dataset) in a single calendar year along with payment data from that and two subsequent years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Gradescope Autograding\n",
    "\n",
    "Please follow [all standard guidance](https://www.practicaldatascience.org/html/autograder_guidelines.html) for submitting this assignment to the Gradescope autograder, including storing your solutions in a dictionary called `results` and ensuring your notebook runs from the start to completion without any errors.\n",
    "\n",
    "For this assignment, please name your file `exercise_passive_prediction.ipynb` before uploading.\n",
    "\n",
    "You can check that you have answers for all questions in your `results` dictionary with this code:\n",
    "\n",
    "```python\n",
    "assert set(results.keys()) == {\n",
    "    \"ex2_merge_type\",\n",
    "    \"ex4_num_mortgages\",\n",
    "    \"ex5_num_obs\",\n",
    "    \"ex7_num_mortgages\",\n",
    "    \"ex7_share_delinquent\",\n",
    "    \"ex10_num_obs\",\n",
    "    \"ex12_roc_auc\",\n",
    "    \"ex14_false_negative_rate\",\n",
    "    \"ex16_num_obs\",\n",
    "    \"ex16_share_delinquent\",\n",
    "    \"ex17_false_negative_rate\",\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### Submission Limits\n",
    "\n",
    "Please remember that you are **only allowed FOUR submissions to the autograder.** Your last submission (if you submit 4 or fewer times), or your third submission (if you submit more than 4 times) will determine your grade Submissions that error out will **not** count against this total.\n",
    "\n",
    "That's one more than usual in case there are issues with exercise clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Organization\n",
    "\n",
    "Data for this exercise can be [found here](https://github.com/nickeubank/MIDS_Data/tree/master/mortgages/2004). This folder includes both the data to be used and documentation, though you can find [supplemental documentation here](https://www.freddiemac.com/research/datasets/sf-loanlevel-dataset).\n",
    "\n",
    "The only difference between this data and the original Freddie Mac sampled data is that I've limited the scope of service data to three calendar years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Begin by loading both: \n",
    "\n",
    "- the mortgage origination file (`sample_orig_2004.txt`). This *should* contain information on all mortgages issued in 2004, along with non-time varying features of these mortgages (the initial amount, the credit score of the applicant, etc.), and \n",
    "- the servicing data (`sample_svcg_2004orig_3years.txt`). This contains monthly records of all recorded payments (or non-payments) for all mortgages issued in 2004 during the calendar years of 2004, 2005, and 2006.\n",
    "\n",
    "So the autograder can see the data, be sure to load it directly from a URL (don't download and load from your own system).\n",
    "\n",
    "Load the data AND ensure your data has column names. You will likely need to reference the documentation to figure out how to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "origination_url = 'https://media.githubusercontent.com/media/nickeubank/MIDS_Data/master/mortgages/2004/sample_orig_2004.txt'\n",
    "servicing_url = 'https://media.githubusercontent.com/media/nickeubank/MIDS_Data/master/mortgages/2004/sample_svcg_2004orig_3years.txt'\n",
    "\n",
    "origination_columns = [ 'credit_score', '1st_payment_date','1st_time_buyer', 'maturity_date', 'msa', 'mi_percent', \n",
    "                        'num_of_units', 'occupancy_status', 'original_cltv', 'original_dti_ratio', 'original_upb', \n",
    "                        'original_ltv', 'original_interest_rt', 'channel', 'ppm_flag', 'amortization_type', \n",
    "                        'property_state', 'property_type', 'postal_code', 'loan_seq_num', 'loan_purpose', \n",
    "                        'original_loan_term', 'num_borrowers', 'seller_name', 'service_name', 'super_conforming', \n",
    "                        'prr_loan_seq_num', 'program_indicator', 'rr_indicator', 'prop_val_method', 'i/o_indicator', \n",
    "                        'mi_cancel_indicator']\n",
    "\n",
    "servicing_columns = ['loan_seq_num', 'monthly_rep_per', 'current_actual_upb', 'current_delinq_status', 'loan_age', \n",
    "                     'month_to_maturity', 'defect_settle_date', 'mod_flag', 'zero_bal_code','zero_bal_eff_data', \n",
    "                     'curr_int_rate', 'curr_non_int_bearing_upb', 'ddlpi', 'mi_recoveries', 'net_sale_proceeds', \n",
    "                     'non_mi_recoveries', 'total_exp', 'legal_costs', 'maint_preserve_costs', 'taxes_insurance', \n",
    "                     'misc_exp', 'actual_loss_cal', 'cum_mod_cost', 'step_mod', 'payment_deferral', 'eltv', \n",
    "                     'zero_bal_rem_upb', 'delinq_acuired_int', 'disaster_delinq', 'borrower_assist_status', \n",
    "                     'curr_month_mod_cost', 'int_bearing_upb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   credit_score  1st_payment_date 1st_time_buyer  maturity_date      msa  \\\n",
      "0           701            200403              N         203402  45060.0   \n",
      "1           648            200403              N         202402      NaN   \n",
      "2           653            200403              Y         203402  20740.0   \n",
      "3           747            200403              N         203402  30700.0   \n",
      "4           731            200403              N         201902      NaN   \n",
      "\n",
      "   mi_percent  num_of_units occupancy_status  original_cltv  \\\n",
      "0          25             1                P             90   \n",
      "1           0             1                P             80   \n",
      "2          17             1                P             87   \n",
      "3           0             2                I             70   \n",
      "4           0             1                P             80   \n",
      "\n",
      "   original_dti_ratio  ...  num_borrowers                         seller_name  \\\n",
      "0                  43  ...              2                       Other sellers   \n",
      "1                  46  ...              1                       Other sellers   \n",
      "2                  25  ...              2                       Other sellers   \n",
      "3                  34  ...              1                       Other sellers   \n",
      "4                  40  ...              2  PROVIDENT FUNDING ASSOCIATES, L.P.   \n",
      "\n",
      "                         service_name super_conforming prr_loan_seq_num  \\\n",
      "0                     Other servicers              NaN              NaN   \n",
      "1                     Other servicers              NaN              NaN   \n",
      "2                     Other servicers              NaN              NaN   \n",
      "3                     Other servicers              NaN              NaN   \n",
      "4  PROVIDENT FUNDING ASSOCIATES, L.P.              NaN              NaN   \n",
      "\n",
      "  program_indicator rr_indicator prop_val_method  i/o_indicator  \\\n",
      "0                 9          NaN               9              N   \n",
      "1                 9          NaN               9              N   \n",
      "2                 9          NaN               9              N   \n",
      "3                 9          NaN               9              N   \n",
      "4                 9          NaN               9              N   \n",
      "\n",
      "  mi_cancel_indicator  \n",
      "0                   9  \n",
      "1                   9  \n",
      "2                   9  \n",
      "3                   9  \n",
      "4                   9  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loading the datasets\"\"\"\n",
    "origination_data = pd.read_csv(origination_url, sep=\"|\", names=origination_columns)\n",
    "\n",
    "servicing_data = pd.read_csv(servicing_url, sep=\"|\", names=servicing_columns)\n",
    "\n",
    "print(origination_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_seq_num  monthly_rep_per  current_actual_upb current_delinq_status  \\\n",
      "0  F04Q10000027           200402            101000.0                     0   \n",
      "1  F04Q10000027           200403            101000.0                     0   \n",
      "2  F04Q10000027           200404            101000.0                     0   \n",
      "3  F04Q10000027           200405            101000.0                     0   \n",
      "4  F04Q10000027           200406            100000.0                     0   \n",
      "\n",
      "   loan_age  month_to_maturity  defect_settle_date mod_flag  zero_bal_code  \\\n",
      "0         0                360                 NaN      NaN            NaN   \n",
      "1         1                359                 NaN      NaN            NaN   \n",
      "2         2                358                 NaN      NaN            NaN   \n",
      "3         3                357                 NaN      NaN            NaN   \n",
      "4         4                356                 NaN      NaN            NaN   \n",
      "\n",
      "   zero_bal_eff_data  ...  cum_mod_cost  step_mod  payment_deferral  eltv  \\\n",
      "0                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "1                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "2                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "3                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "4                NaN  ...           NaN       NaN               NaN   NaN   \n",
      "\n",
      "   zero_bal_rem_upb  delinq_acuired_int  disaster_delinq  \\\n",
      "0               NaN                 NaN              NaN   \n",
      "1               NaN                 NaN              NaN   \n",
      "2               NaN                 NaN              NaN   \n",
      "3               NaN                 NaN              NaN   \n",
      "4               NaN                 NaN              NaN   \n",
      "\n",
      "   borrower_assist_status  curr_month_mod_cost  int_bearing_upb  \n",
      "0                     NaN                  NaN         101000.0  \n",
      "1                     NaN                  NaN         101000.0  \n",
      "2                     NaN                  NaN         101000.0  \n",
      "3                     NaN                  NaN         101000.0  \n",
      "4                     NaN                  NaN         100000.0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(servicing_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "What is the unit of observation in `sample_orig_2004.txt` and in `sample_svcg_2004orig_3years.txt`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "* 1. In the **origination data file (`sample_orig_2004.txt`)** each row represents a unique mortgage loan at the time of origination. Therefore the unit observation is a loan.\n",
    "* 2. The **servicing data file (`sample_svcg_2004orig_3years.txt`)** includes servicing data on the unit of observation mention in the previous paragraph. So it is a monthly record of a mortgage loan's payment status. Each row in this dataset represents specific information for a specific loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Merge your two datasets. Be sure to use the `validate` keyword argument in `merge`.\n",
    "\n",
    "Assuming that you list the data associated with `sample_orig_2004.txt` first and `sample_svcg_2004orig_3years.txt` second, what keyword are you passing to `validate`? Store your answer as a string (use one of: `\"1:1\"`, `\"m:1\"`, `\"1:m\"`, `\"m:m\"`) in a dictionary called `results` under the key `ex2_merge_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"merging data as per instruction\"\"\"\n",
    "merged_data = origination_data.merge(servicing_data, on='loan_seq_num', validate='1:m')\n",
    "\n",
    "results = {'ex2_merge_type': '1:m'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   credit_score  1st_payment_date 1st_time_buyer  maturity_date      msa  \\\n",
      "0           701            200403              N         203402  45060.0   \n",
      "1           701            200403              N         203402  45060.0   \n",
      "2           701            200403              N         203402  45060.0   \n",
      "3           701            200403              N         203402  45060.0   \n",
      "4           701            200403              N         203402  45060.0   \n",
      "\n",
      "   mi_percent  num_of_units occupancy_status  original_cltv  \\\n",
      "0          25             1                P             90   \n",
      "1          25             1                P             90   \n",
      "2          25             1                P             90   \n",
      "3          25             1                P             90   \n",
      "4          25             1                P             90   \n",
      "\n",
      "   original_dti_ratio  ...  cum_mod_cost  step_mod  payment_deferral eltv  \\\n",
      "0                  43  ...           NaN       NaN               NaN  NaN   \n",
      "1                  43  ...           NaN       NaN               NaN  NaN   \n",
      "2                  43  ...           NaN       NaN               NaN  NaN   \n",
      "3                  43  ...           NaN       NaN               NaN  NaN   \n",
      "4                  43  ...           NaN       NaN               NaN  NaN   \n",
      "\n",
      "  zero_bal_rem_upb delinq_acuired_int disaster_delinq borrower_assist_status  \\\n",
      "0              NaN                NaN             NaN                    NaN   \n",
      "1              NaN                NaN             NaN                    NaN   \n",
      "2              NaN                NaN             NaN                    NaN   \n",
      "3              NaN                NaN             NaN                    NaN   \n",
      "4              NaN                NaN             NaN                    NaN   \n",
      "\n",
      "   curr_month_mod_cost int_bearing_upb  \n",
      "0                  NaN        101000.0  \n",
      "1                  NaN        101000.0  \n",
      "2                  NaN        101000.0  \n",
      "3                  NaN        101000.0  \n",
      "4                  NaN        100000.0  \n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Mortgages come in many shapes and flavors, however your servicer is only interested in predicting default for the more standard form of mortgage. Subset your data to only include:\n",
    "\n",
    "- Mortgages taken out for purchase of a property,\n",
    "- With first payments due in the quarter of origination or the first quarter after origination.\n",
    "\n",
    "(In a perfect world we would just limit our analysis to mortgages where the first payment is due the month after origination. Unfortunately we only know the *quarter* of origination, so the only way to subset for relatively vanilla mortgages is to look for mortgages where the first payment was due in the same quarter or the quarter after origination.)\n",
    "\n",
    "Subset for these mortgages. How many unique mortgages remain in the data? \n",
    "\n",
    "Hint: You may need to read the documentation for the `Loan Sequence Number` variable.\n",
    "\n",
    "Store the resulting number of unique mortgages in `results` under the key `ex4_num_mortgages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454824\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Step 1. subset on purchase purpose \"\"\"\n",
    "purpose_subset = merged_data[merged_data['loan_purpose'] == 'P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Loan sequence number understanding\"\"\"\n",
    "# PYYQnXXXXXXX\n",
    "# YYQn = origination year and quarter; and,\n",
    "# XXXXXXX = randomly assigned digits - UNIQUE\n",
    "# Type: Alpha-numeric\n",
    "\n",
    "\"\"\"FIRST PAYMENT DATE understanding\"\"\"\n",
    "# The date of the first scheduled mortgage payment due under the terms of the mortgage note.\n",
    "# YYYYMM \n",
    "# Type: Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2004']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Step 2. job related to creating the new columns\"\"\"\n",
    "# 1. Origination Year\n",
    "purpose_subset['origination_year'] = '20' + purpose_subset['loan_seq_num'].str[1:3]\n",
    "\n",
    "print(purpose_subset['origination_year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# 2. Origination Quarter\n",
    "purpose_subset['origin_quarter'] = purpose_subset['loan_seq_num'].str[4].astype(int)\n",
    "\n",
    "print(purpose_subset['origin_quarter'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2004' '2005' '2006']\n"
     ]
    }
   ],
   "source": [
    "# 4. Payment Year\n",
    "purpose_subset['payment_year'] = purpose_subset['1st_payment_date'].astype(str).str[:4]\n",
    "\n",
    "print(purpose_subset['payment_year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2' '3' '4']\n"
     ]
    }
   ],
   "source": [
    "# 5. Payment Quarter\n",
    "purpose_subset['1st_payment_date'] = purpose_subset['1st_payment_date'].astype(str)\n",
    "\n",
    "def calculate_payment_quarter(month):\n",
    "    if month in ['01', '02', '03']:\n",
    "        return '1'\n",
    "    elif month in ['04', '05', '06']:\n",
    "        return '2'\n",
    "    elif month in ['07', '08', '09']:\n",
    "        return '3'\n",
    "    elif month in ['10', '11', '12']:\n",
    "        return '4'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "purpose_subset['payment_quarter'] = purpose_subset['1st_payment_date'].str[-2:].apply(calculate_payment_quarter)\n",
    "\n",
    "print(purpose_subset['payment_quarter'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449710\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Step 3. subsetting \"\"\"\n",
    "\n",
    "# Define the conditions\n",
    "condition1 = (purpose_subset['origination_year'] == '2004') & \\\n",
    "             (purpose_subset['payment_year'] == '2004') & \\\n",
    "             (purpose_subset['origin_quarter'] == purpose_subset['payment_quarter'])\n",
    "\n",
    "condition2 = (purpose_subset['origination_year'] == '2004') & \\\n",
    "             (purpose_subset['payment_year'] == '2004') & \\\n",
    "             (purpose_subset['origin_quarter'] + 1 == purpose_subset['payment_quarter'])\n",
    "\n",
    "condition3 = (purpose_subset['origination_year'] == '2004') & \\\n",
    "             (purpose_subset['origin_quarter'] == 4) & \\\n",
    "             (purpose_subset['payment_year'] == '2005') & \\\n",
    "             (purpose_subset['payment_quarter'] == 1)\n",
    "\n",
    "# Combine conditions to subset the DataFrame\n",
    "mortgage_subset = purpose_subset[condition1 | condition2 | condition3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique_mortgages for purchase with the first payments due on the quarter of origination or the quarter after is 17504\n",
      "{'ex2_merge_type': '1:m', 'ex4_num_mortgages': 17504}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Step 4. unique number\"\"\"\n",
    "unique_mortgage = mortgage_subset['loan_seq_num'].nunique()\n",
    "results['ex4_num_mortgages'] = unique_mortgage\n",
    "\n",
    "print(f\"Number of unique_mortgages for purchase with the first payments due on the quarter of origination or the quarter after is {unique_mortgage}\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "The servicer wants to predict delinquency during the first 24 payment due dates (you may assume payments are due every month starting with the month the first payment is due). Subset the data to these first 24 (possible) payment due dates.\n",
    "\n",
    "Note that not all loans will have 24 records in the servicing file in the first 24 months as a result of data merging issues on behalf of Freddie Mac. As noted in the Freddie Mac documentation:\n",
    "\n",
    "> For a given loan, each monthly reporting period in the monthly performance data file combines data elements from multiple reporting cycles and systems at Freddie Mac. As such, perceived data anomalies may be a result of timing mismatches between default/delinquency reporting cycles and investor reporting cycles. Examples of some commonly occurring anomalies in the data are included throughout this section. In all cases, the best information available at the time the Dataset is generated, subject to operational constraints, is used.\n",
    "\n",
    "So subset for the first two years of (possible) payments, resulting in *up to* 24 observations per mortgage (but potentially less given the data cleanliness issues).\n",
    "\n",
    "After this subsetting, store the number of remaining observations (not mortgages, observation) in `results` under the key `\"ex5_num_obs\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "For each unique mortgage in your dataset, create an indicator variable that takes on a value of 1 if, at any time during this period, the mortgage has been delinquent.\n",
    "\n",
    "Delinquency status is stored in the variable `CURRENT LOAN DELINQUENCY STATUS`, and is coded as:\n",
    "\n",
    "> CURRENT LOAN DELINQUENCY STATUS – A value corresponding to the number of days the borrower is delinquent, based on the due date of last paid installment (“DDLPI”) reported by servicers to Freddie Mac, and is calculated under the Mortgage Bankers Association (MBA) method.\n",
    "If a loan has been acquired by REO, then the Current Loan Delinquency Status will reflect the value corresponding to that status (instead of the value corresponding to the number of days the borrower is delinquent).\n",
    ">\n",
    "> 0 = Current, or less than 30 days delinquent\n",
    "> \n",
    "> 1 = 30-59 days delinquent\n",
    "> \n",
    "> 2=60–89days delinquent\n",
    "> \n",
    "> 3=90–119days delinquent\n",
    "> \n",
    "> And so on...\n",
    "> \n",
    "> RA = REO Acquisition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "At this point, you should be able to drop all servicing variables reported on a monthly basis and just keep information about the original mortgage issuance (and still keep an indicator for whether the mortgage has ever been delinquent).\n",
    "\n",
    "Store the final number of mortgages in your data under `ex7_num_mortgages` and the share (between 0 and 1) of mortgages that have been delinquent under `ex7_share_delinquent`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Delinquency Risk\n",
    "\n",
    "Your data should now be relatively [tidy](https://vita.had.co.nz/papers/tidy-data.pdf), in the technical sense of the term. And that means it should be relatively straightforward for you to build a model that answers the question \"Given the features of a newly originated mortgage, how likely is the mortgage holder to fall into delinquency within the first two years after origination?\"\n",
    "\n",
    "### Exercise 8\n",
    "\n",
    "First, we need to identify the target for our model useful predictors from the data and do feature engineering.\n",
    "\n",
    "Let's begin with identifying some features that probably *aren't* going to be useful. For example, `\"Metropolitan Statistical Area (MSA) Or Metropolitan Division\"` is probably *not* an appropriate feature to include in this analysis. Can you figure out why? Make sure to show (quantitatively) why not. \n",
    "\n",
    "Hint: should be more than the missing rate.\n",
    "\n",
    "Hint 2: how many observations for a given city do you think you'd need to determine if that city had especially high mortgage delinquency rates?\n",
    "\n",
    "Hint 3: if not all possible values of a variable are present in your training data, what problem might that cause during testing and deployment?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "For your analysis, include the following variables: \n",
    "\n",
    "```\n",
    "Credit Score\n",
    "First Time Homebuyer Flag\n",
    "Number of Units\n",
    "Mortgage Insurance Percentage (MI %)\n",
    "Occupancy Status\n",
    "Original Debt-to-Income (DTI) Ratio\n",
    "Original UPB\n",
    "Original Loan-to-Value (LTV)\n",
    "Original Interest Rate\n",
    "Channel\n",
    "Prepayment Penalty Mortgage (PPM) Flag\n",
    "Amortization Type (Formerly Product Type)\n",
    "Property State\n",
    "Property Type\n",
    "Original Loan Term\n",
    "Number of Borrowers\n",
    "Interest Only (I/O) Indicator\n",
    "```\n",
    "\n",
    "Be sure to clean these variables. When doing so, please treat missing data as missing (e.g., `np.nan`, not as a distinct category)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "The next step in our analysis is to convert our categorical variables to one-hot-encodings and use `train_test_split` to split our data.\n",
    "\n",
    "To ensure replicability, **before** you `train_test_split` your data, please sort your data by `Loan Sequence Number`. This will ensure when we split the data with a random seed below, everyone will get the same split and the autograder will function.\n",
    "\n",
    "You may create your one-hot-encodings however you wish, but I'm a fan of the [patsy library's](https://patsy.readthedocs.io/en/latest/overview.html) `dmatrices` function.\n",
    "\n",
    "Hint: You should end up with 8 categorical variables, including some binary flags and `Number_of_Borrowers`, `Number_of_Units` (which you could argue should be continuous, but I think are better treated as categorical).\n",
    "\n",
    "Store the number of observations in your final dataset in `ex10_num_obs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "\n",
    "Use `train_test_split` from `sklearn.model_selection` to split the data. \n",
    "\n",
    "Before you do, Use `0.2` as the `test_size` and use `random_state=42`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "\n",
    "Now fit a `GradientBoostingClassifier` to the data (from `sklearn.ensemble`). Set `random_state=42`. using `roc_auc_score`, get your ROC AUC score against the test data. Store in `results` under the key `\"ex12_roc_auc\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13\n",
    "\n",
    "Use the `predict` method to generate a confusion matrix. What problem do you see with the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14\n",
    "\n",
    "To address the problem from Exercise 13, use `.predict_proba()` to set your own threshold for classification. Your stakeholder is mostly concerned with False Negatives (mortgages classified as safe that actually are not), so use a 8% probability threshold to get a good balance of a low False Negative rate with a reasonable amount of mortgages still being considered \"viable.\"\n",
    "\n",
    "What is the False Negative rate at an 8% classification threshold from the model above?\n",
    "\n",
    "Store the result under the key `\"ex14_false_negative_rate\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 15\n",
    "\n",
    "Your stakeholder wants to by as many mortgages as it can while maintaining a delinquency rate of purchased mortgages below 5%. Based on your answer above, do you feel like your model can provide that level of performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now To The Future\n",
    "\n",
    "The preceding analysis is precisely the type of analysis you would do if, in late 2006, you'd been asked to evaluate mortgage performance in the last two years for use going forward. So let's see how your model performs now!\n",
    "\n",
    "In this [folder](https://github.com/nickeubank/MIDS_Data/tree/master/mortgages/2007) you will find data on mortgages originated in 2007 along with servicing data from 2007, 2008, and 2009.\n",
    "\n",
    "### Exercise 16\n",
    "\n",
    "Please load this data (again, from a URL to help the autograder) and clean it in the same manner as before. As a sanity check, how many observations do you have in the final dataset (after you've removed observations with missing values to allow you to generate predicted delinquency rates)? \n",
    "\n",
    "Store the final number of observations in `\"ex16_num_obs\"` and the share of those mortgages that are delinquent in `\"ex16_share_delinquent\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 17\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had your stakeholder purchased mortgages using your model, what would the resulting False Negative rate have been? (e.g., compare the predicted values for mortgages using the model trained above with realized outcomes). Store your result under the key `\"ex17_false_negative_rate\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 18\n",
    "\n",
    "How did the retrospective performance of your model compare to its actual performance moving forward? Why? Did you stay below the 5% target for False Negatives set by the stakeholder?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
